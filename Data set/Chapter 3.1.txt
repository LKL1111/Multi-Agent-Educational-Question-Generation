 3.1 Introduction and Transport-Layer Services
 In the previous two chapters we touched on the role of the transport layer and the 
services that it provides. Let’s quickly review what we have already learned about 
the transport layer.
 A transport-layer protocol provides for logical communication between 
application processes running on different hosts. By logical communication, we 
mean that from an application’s perspective, it is as if the hosts running the pro
cesses were directly connected; in reality, the hosts may be on opposite sides of the 
planet, connected via numerous routers and a wide range of link types. Application 
processes use the logical communication provided by the transport layer to send 
messages to each other, free from the worry of the details of the physical infra
structure used to carry these messages. Figure 3.1 illustrates the notion of logical 
communication.
 As shown in Figure 3.1, transport-layer protocols are implemented in the end 
systems but not in network routers. On the sending side, the transport layer converts 
the application-layer messages it receives from a sending application process into 
transport-layer packets, known as transport-layer segments in Internet terminology. 
This is done by (possibly) breaking the application messages into smaller chunks 
and adding a transport-layer header to each chunk to create the transport-layer seg
ment. The transport layer then passes the segment to the network layer at the send
ing end system, where the segment is encapsulated within a network-layer packet (a 
datagram) and sent to the destination. It’s important to note that network routers act 
only on the network-layer fields of the datagram; that is, they do not examine the 
fields of the transport-layer segment encapsulated with the datagram. On the receiv
ing side, the network layer extracts the transport-layer segment from the datagram 
and passes the segment up to the transport layer. The transport layer then processes 
the received segment, making the data in the segment available to the receiving 
application.
 More than one transport-layer protocol may be available to network applications. 
For example, the Internet has two protocols—TCP and UDP. Each of these protocols 
provides a different set of transport-layer services to the invoking application.
 3.1.1 Relationship Between Transport and Network Layers
 Recall that the transport layer lies just above the network layer in the protocol 
stack. Whereas a transport-layer protocol provides logical communication between
 processes running on different hosts, a network-layer protocol provides logical- 
communication between hosts. This distinction is subtle but important. Let’s exam
ine this distinction with the aid of a household analogy.
 Consider two houses, one on the East Coast and the other on the West Coast, 
with each house being home to a dozen kids. The kids in the East Coast household 
are cousins of the kids in the West Coast household. The kids in the two households 
love to write to each other—each kid writes each cousin every week, with each letter 
delivered by the traditional postal service in a separate envelope. Thus, each house
hold sends 144 letters to the other household every week. (These kids would save a lot 
of money if they had e-mail!) In each of the households there is one kid—Ann in the 
West Coast house and Bill in the East Coast house—responsible for mail collection  
and mail distribution. Each week Ann visits all her brothers and sisters, collects the 
mail, and gives the mail to a postal-service mail carrier, who makes daily visits to 
the house. When letters arrive at the West Coast house, Ann also has the job of dis
tributing the mail to her brothers and sisters. Bill has a similar job on the East Coast.
 In this example, the postal service provides logical communication between the 
two houses—the postal service moves mail from house to house, not from person to 
person. On the other hand, Ann and Bill provide logical communication among the 
cousins—Ann and Bill pick up mail from, and deliver mail to, their brothers and sis
ters. Note that from the cousins’ perspective, Ann and Bill are the mail service, even 
though Ann and Bill are only a part (the end-system part) of the end-to-end delivery 
process. This household example serves as a nice analogy for explaining how the 
transport layer relates to the network layer:
 application messages = letters in envelopes
 processes = cousins
 hosts (also called end systems) = houses
 transport-layer protocol = Ann and Bill
 network-layer protocol = postal service (including mail carriers)
 Continuing with this analogy, note that Ann and Bill do all their work within 
their respective homes; they are not involved, for example, in sorting mail in 
any intermediate mail center or in moving mail from one mail center to another.  
Similarly, transport-layer protocols live in the end systems. Within an end system, a 
transport protocol moves messages from application processes to the network edge 
(that is, the network layer) and vice versa, but it doesn’t have any say about how the 
messages are moved within the network core. In fact, as illustrated in Figure 3.1, 
intermediate routers neither act on, nor recognize, any information that the transport 
layer may have added to the application messages.
 Continuing with our family saga, suppose now that when Ann and Bill go on 
vacation, another cousin pair—say, Susan and Harvey—substitute for them and pro
vide the household-internal collection and delivery of mail. Unfortunately for the 
two families, Susan and Harvey do not do the collection and delivery in exactly 
 the same way as Ann and Bill. Being younger kids, Susan and Harvey pick up and 
drop off the mail less frequently and occasionally lose letters (which are sometimes 
chewed up by the family dog). Thus, the cousin-pair Susan and Harvey do not pro
vide the same set of services (that is, the same service model) as Ann and Bill. In 
an analogous manner, a computer network may make available multiple transport 
protocols, with each protocol offering a different service model to applications.
 The possible services that Ann and Bill can provide are clearly constrained by 
the possible services that the postal service provides. For example, if the postal ser
vice doesn’t provide a maximum bound on how long it can take to deliver mail 
between the two houses (for example, three days), then there is no way that Ann and 
Bill can guarantee a maximum delay for mail delivery between any of the cousin 
pairs. In a similar manner, the services that a transport protocol can provide are often 
constrained by the service model of the underlying network-layer protocol. If the 
network-layer protocol cannot provide delay or bandwidth guarantees for transport
layer segments sent between hosts, then the transport-layer protocol cannot provide 
delay or bandwidth guarantees for application messages sent between processes.
 Nevertheless, certain services can be offered by a transport protocol even when 
the underlying network protocol doesn’t offer the corresponding service at the net
work layer. For example, as we’ll see in this chapter, a transport protocol can offer 
reliable data transfer service to an application even when the underlying network 
protocol is unreliable, that is, even when the network protocol loses, garbles, or 
duplicates packets. As another example (which we’ll explore in Chapter 8 when we 
discuss network security), a transport protocol can use encryption to guarantee that 
application messages are not read by intruders, even when the network layer cannot 
guarantee the confidentiality of transport-layer segments.
 3.1.2 Overview of the Transport Layer in the Internet
 Recall that the Internet makes two distinct transport-layer protocols available to the 
application layer. One of these protocols is UDP (User Datagram Protocol), which 
provides an unreliable, connectionless service to the invoking application. The sec
ond of these protocols is TCP (Transmission Control Protocol), which provides a 
reliable, connection-oriented service to the invoking application. When designing a 
network application, the application developer must specify one of these two trans
port protocols. As we saw in Section 2.7, the application developer selects between 
UDP and TCP when creating sockets.
 To simplify terminology, we refer to the transport-layer packet as a segment. We 
mention, however, that the Internet literature (for example, the RFCs) also refers to 
the transport-layer packet for TCP as a segment but often refers to the packet for UDP 
as a datagram. But this same Internet literature also uses the term datagram for the 
network-layer packet! For an introductory book on computer networking such as this, 
we believe that it is less confusing to refer to both TCP and UDP packets as segments, 
and reserve the term datagram for the network-layer packet.
Before proceeding with our brief introduction of UDP and TCP, it will be useful 
to say a few words about the Internet’s network layer. (We’ll learn about the network 
layer in detail in Chapters 4 and 5.) The Internet’s network-layer protocol has a 
name—IP, for Internet Protocol. IP provides logical communication between hosts. 
The IP service model is a best-effort delivery service. This means that IP makes 
its “best effort” to deliver segments between communicating hosts, but it makes no 
guarantees. In particular, it does not guarantee segment delivery, it does not guaran
tee orderly delivery of segments, and it does not guarantee the integrity of the data 
in the segments. For these reasons, IP is said to be an unreliable service. We also 
mention here that every host has at least one network-layer address, a so-called IP 
address. We’ll examine IP addressing in detail in Chapter 4; for this chapter we need 
only keep in mind that each host has an IP address.
 Having taken a glimpse at the IP service model, let’s now summarize the service 
models provided by UDP and TCP. The most fundamental responsibility of UDP 
and TCP is to extend IP’s delivery service between two end systems to a delivery 
service between two processes running on the end systems. Extending host-to-host 
delivery to process-to-process delivery is called transport-layer multiplexing and  
demultiplexing. We’ll discuss transport-layer multiplexing and demultiplexing in 
the next section. UDP and TCP also provide integrity checking by including error
detection fields in their segments’ headers. These two minimal transport-layer 
services—process-to-process data delivery and error checking—are the only two 
services that UDP provides! In particular, like IP, UDP is an unreliable service—it 
does not guarantee that data sent by one process will arrive intact (or at all!) to the 
destination process. UDP is discussed in detail in Section 3.3.
 TCP, on the other hand, offers several additional services to applications. First 
and foremost, it provides reliable data transfer. Using flow control, sequence 
numbers, acknowledgments, and timers (techniques we’ll explore in detail in this 
chapter), TCP ensures that data is delivered from sending process to receiving pro
cess, correctly and in order. TCP thus converts IP’s unreliable service between end 
systems into a reliable data transport service between processes. TCP also provides 
congestion control. Congestion control is not so much a service provided to the 
invoking application as it is a service for the Internet as a whole, a service for the 
general good. Loosely speaking, TCP congestion control prevents any one TCP con
nection from swamping the links and routers between communicating hosts with 
an excessive amount of traffic. TCP strives to give each connection traversing a 
congested link an equal share of the link bandwidth. This is done by regulating the 
rate at which the sending sides of TCP connections can send traffic into the network. 
UDP traffic, on the other hand, is unregulated. An application using UDP transport 
can send at any rate it pleases, for as long as it pleases.
 A protocol that provides reliable data transfer and congestion control is neces
sarily complex. We’ll need several sections to cover the principles of reliable data 
transfer and congestion control, and additional sections to cover the TCP protocol 
itself. These topics are investigated in Sections 3.4 through 3.8. The approach taken
 in this chapter is to alternate between basic principles and the TCP protocol. For 
example, we’ll first discuss reliable data transfer in a general setting and then discuss 
how TCP specifically provides reliable data transfer. Similarly, we’ll first discuss 
congestion control in a general setting and then discuss how TCP performs conges
tion control. But before getting into all this good stuff, let’s first look at transport
layer multiplexing and demultiplexing.
 3.2 Multiplexing and Demultiplexing
 In this section, we discuss transport-layer multiplexing and demultiplexing, that 
is, extending the host-to-host delivery service provided by the network layer to a  
process-to-process delivery service for applications running on the hosts. In order to 
keep the discussion concrete, we’ll discuss this basic transport-layer service in the 
context of the Internet. We emphasize, however, that a multiplexing/demultiplexing 
service is needed for all computer networks.
 At the destination host, the transport layer receives segments from the network 
layer just below. The transport layer has the responsibility of delivering the data in 
these segments to the appropriate application process running in the host. Let’s take 
a look at an example. Suppose you are sitting in front of your computer, and you are 
downloading Web pages while running one FTP session and two Telnet sessions. 
You therefore have four network application processes running—two Telnet pro
cesses, one FTP process, and one HTTP process. When the transport layer in your 
computer receives data from the network layer below, it needs to direct the received 
data to one of these four processes. Let’s now examine how this is done.
 First recall from Section 2.7 that a process (as part of a network application) 
can have one or more sockets, doors through which data passes from the network to 
the process and through which data passes from the process to the network. Thus, 
as shown in Figure 3.2, the transport layer in the receiving host does not actually 
deliver data directly to a process, but instead to an intermediary socket. Because at 
any given time there can be more than one socket in the receiving host, each socket 
has a unique identifier. The format of the identifier depends on whether the socket is 
a UDP or a TCP socket, as we’ll discuss shortly.
 Now let’s consider how a receiving host directs an incoming transport-layer 
segment to the appropriate socket. Each transport-layer segment has a set of fields in 
the segment for this purpose. At the receiving end, the transport layer examines these 
fields to identify the receiving socket and then directs the segment to that socket. 
This job of delivering the data in a transport-layer segment to the correct socket is 
called demultiplexing. The job of gathering data chunks at the source host from 
different sockets, encapsulating each data chunk with header information (that will 
later be used in demultiplexing) to create segments, and passing the segments to the 
network layer is called multiplexing. Note that the transport layer in the middle host
 in Figure 3.2 must demultiplex segments arriving from the network layer below to 
either process P1 or P2 above; this is done by directing the arriving segment’s data to 
the corresponding process’s socket. The transport layer in the middle host must also 
gather outgoing data from these sockets, form transport-layer segments, and pass 
these segments down to the network layer. Although we have introduced multiplex
ing and demultiplexing in the context of the Internet transport protocols, it’s impor
tant to realize that they are concerns whenever a single protocol at one layer (at the 
transport layer or elsewhere) is used by multiple protocols at the next higher layer.
 To illustrate the demultiplexing job, recall the household analogy in the previous 
section. Each of the kids is identified by his or her name. When Bill receives a batch 
of mail from the mail carrier, he performs a demultiplexing operation by observing 
to whom the letters are addressed and then hand delivering the mail to his brothers 
and sisters. Ann performs a multiplexing operation when she collects letters from her 
brothers and sisters and gives the collected mail to the mail person.
 Now that we understand the roles of transport-layer multiplexing and demulti
plexing, let us examine how it is actually done in a host. From the discussion above, 
we know that transport-layer multiplexing requires (1) that sockets have unique 
identifiers, and (2) that each segment have special fields that indicate the socket to 
which the segment is to be delivered. These special fields, illustrated in Figure 3.3, 
are the source port number field and the destination port number field. (The UDP 
and TCP segments have other fields as well, as discussed in the subsequent sections 
of this chapter.) Each port number is a 16-bit number, ranging from 0 to 65535. 
The port numbers ranging from 0 to 1023 are called well-known port numbers  
and are restricted, which means that they are reserved for use by well-known 
 application protocols such as HTTP (which uses port number 80) and FTP (which 
uses port number 21). The list of well-known port numbers is given in RFC 1700 
and is updated at http://www.iana.org [RFC 3232]. When we develop a new appli
cation (such as the simple application developed in Section 2.7), we must assign the 
application a port number.
 It should now be clear how the transport layer could implement the demultiplex
ing service: Each socket in the host could be assigned a port number, and when 
a segment arrives at the host, the transport layer examines the destination port 
number in the segment and directs the segment to the corresponding socket. The 
segment’s data then passes through the socket into the attached process. As we’ll 
see, this is basically how UDP does it. However, we’ll also see that multiplexing/
 demultiplexing in TCP is yet more subtle.
 Connectionless Multiplexing and Demultiplexing
 Recall from Section 2.7.1 that the Python program running in a host can create a 
UDP socket with the line
 clientSocket = socket(AF_INET, SOCK_DGRAM)
 When a UDP socket is created in this manner, the transport layer automatically 
assigns a port number to the socket. In particular, the transport layer assigns a port 
number in the range 1024 to 65535 that is currently not being used by any other UDP 
port in the host. Alternatively, we can add a line into our Python program after we 
create the socket to associate a specific port number (say, 19157) to this UDP socket 
via the socket bind() method:
 clientSocket.bind((’’, 19157))
 If the application developer writing the code were implementing the server side of 
a “well-known protocol,” then the developer would have to assign the correspond
ing well-known port number. Typically, the client side of the application lets the 
transport layer automatically (and transparently) assign the port number, whereas the 
server side of the application assigns a specific port number.
 With port numbers assigned to UDP sockets, we can now precisely describe 
UDP multiplexing/demultiplexing. Suppose a process in Host A, with UDP port 
19157, wants to send a chunk of application data to a process with UDP port 46428 in 
Host B. The transport layer in Host A creates a transport-layer segment that includes 
the application data, the source port number (19157), the destination port number 
(46428), and two other values (which will be discussed later, but are unimportant for 
the current discussion). The transport layer then passes the resulting segment to the 
network layer. The network layer encapsulates the segment in an IP datagram and 
makes a best-effort attempt to deliver the segment to the receiving host. If the seg
ment arrives at the receiving Host B, the transport layer at the receiving host exam
ines the destination port number in the segment (46428) and delivers the segment 
to its socket identified by port 46428. Note that Host B could be running multiple 
processes, each with its own UDP socket and associated port number. As UDP seg
ments arrive from the network, Host B directs (demultiplexes) each segment to the 
appropriate socket by examining the segment’s destination port number.
 It is important to note that a UDP socket is fully identified by a two-tuple consist
ing of a destination IP address and a destination port number. As a consequence, if 
two UDP segments have different source IP addresses and/or source port numbers, but 
have the same destination IP address and destination port number, then the two seg
ments will be directed to the same destination process via the same destination socket.
 You may be wondering now, what is the purpose of the source port number? 
As shown in Figure 3.4, in the A-to-B segment the source port number serves as 
part of a “return address”—when B wants to send a segment back to A, the destina
tion port in the B-to-A segment will take its value from the source port value of the 
A-to-B segment. (The complete return address is A’s IP address and the source port 
number.) As an example, recall the UDP server program studied in Section 2.7. In 
UDPServer.py, the server uses the recvfrom() method to extract the client
side (source) port number from the segment it receives from the client; it then sends 
a new segment to the client, with the extracted source port number serving as the 
destination port number in this new segment.
 Connection-Oriented Multiplexing and Demultiplexing
 In order to understand TCP demultiplexing, we have to take a close look at TCP 
sockets and TCP connection establishment. One subtle difference between a 
TCP socket and a UDP socket is that a TCP socket is identified by a four-tuple: 
(source IP address, source port number, destination IP address, destination port 
number). Thus, when a TCP segment arrives from the network to a host, the host 
uses all four values to direct (demultiplex) the segment to the appropriate socket. 
 In particular, and in contrast with UDP, two arriving TCP segments with differ
ent source IP addresses or source port numbers will (with the exception of a TCP 
segment carrying the original connection-establishment request) be directed to two 
different sockets. To gain further insight, let’s reconsider the TCP client-server pro
gramming example in Section 2.7.2:
 • The TCP server application has a “welcoming socket,” that waits for connection
establishment requests from TCP clients (see Figure 2.29) on port number 12000.
 • The TCP client creates a socket and sends a connection establishment request 
segment with the lines:
 clientSocket = socket(AF_INET, SOCK_STREAM)
 clientSocket.connect((serverName,12000))
 • A connection-establishment request is nothing more than a TCP segment with 
destination port number 12000 and a special connection-establishment bit set in 
the TCP header (discussed in Section 3.5). The segment also includes a source 
port number that was chosen by the client.
 • When the host operating system of the computer running the server process 
receives the incoming connection-request segment with destination port 12000, 
it locates the server process that is waiting to accept a connection on port number 
12000. The server process then creates a new socket:
 connectionSocket, addr = serverSocket.accept()
 • Also, the transport layer at the server notes the following four values in the con
nection-request segment: (1) the source port number in the segment, (2) the IP 
address of the source host, (3) the destination port number in the segment, and 
(4) its own IP address. The newly created connection socket is identified by these 
four values; all subsequently arriving segments whose source port, source IP 
address, destination port, and destination IP address match these four values will 
be demultiplexed to this socket. With the TCP connection now in place, the client 
and server can now send data to each other.
 The server host may support many simultaneous TCP connection sockets, with 
each socket attached to a process, and with each socket identified by its own four
tuple. When a TCP segment arrives at the host, all four fields (source IP address, 
source port, destination IP address, destination port) are used to direct (demultiplex) 
the segment to the appropriate socket
 The situation is illustrated in Figure 3.5, in which Host C initiates two HTTP 
sessions to server B, and Host A initiates one HTTP session to B. Hosts A and C 
and server B each have their own unique IP address—A, C, and B, respectively. 
Host C assigns two different source port numbers (26145 and 7532) to its two HTTP 
connections. Because Host A is choosing source port numbers independently of C, 
it might also assign a source port of 26145 to its HTTP connection. But this is not 
a problem—server B will still be able to correctly demultiplex the two connections 
having the same source port number, since the two connections have different source 
IP addresses.
 Web Servers and TCP
 Before closing this discussion, it’s instructive to say a few additional words about 
Web servers and how they use port numbers. Consider a host running a Web server, 
such as an Apache Web server, on port 80. When clients (for example, browsers) 
send segments to the server, all segments will have destination port 80. In particular, 
both the initial connection-establishment segments and the segments carrying HTTP 
 request messages will have destination port 80. As we have just described, the server 
distinguishes the segments from the different clients using source IP addresses and 
source port numbers.
 Figure 3.5 shows a Web server that spawns a new process for each connec
tion. As shown in Figure 3.5, each of these processes has its own connection socket 
through which HTTP requests arrive and HTTP responses are sent. We mention, 
however, that there is not always a one-to-one correspondence between connection 
sockets and processes. In fact, today’s high-performing Web servers often use only 
one process, and create a new thread with a new connection socket for each new 
client connection. (A thread can be viewed as a lightweight subprocess.) If you did 
the first programming assignment in Chapter 2, you built a Web server that does just 
this. For such a server, at any given time there may be many connection sockets (with 
different identifiers) attached to the same process.
 If the client and server are using persistent HTTP, then throughout the duration 
of the persistent connection the client and server exchange HTTP messages via the 
same server socket. However, if the client and server use non-persistent HTTP, then 
a new TCP connection is created and closed for every request/response, and hence 
a new socket is created and later closed for every request/response. This frequent 
creating and closing of sockets can severely impact the performance of a busy Web 
server (although a number of operating system tricks can be used to mitigate the 
problem). Readers interested in the operating system issues surrounding persistent 
and non-persistent HTTP are encouraged to see [Nielsen 1997; Nahum 2002].
 Now that we’ve discussed transport-layer multiplexing and demultiplexing, let’s 
move on and discuss one of the Internet’s transport protocols, UDP. In the next sec
tion we’ll see that UDP adds little more to the network-layer protocol than a multi
plexing/demultiplexing service.